{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CelebA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* site : http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download & Load CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SavePath = 'CelebA_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(SavePath):\n",
    "    # Dropbox Link can be terminated\n",
    "    link = 'https://www.dropbox.com/s/gxjc9p7s6xmo09k/CelebA_Align.zip?dl=1'\n",
    "    url = urllib.request.urlopen(link)\n",
    "\n",
    "    filesize = int(url.headers['Content-Length'])\n",
    "    filename = 'CelebA_Align.zip'\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        downloaded = 0\n",
    "        block_size = 8192\n",
    "        status_width = 70\n",
    "        while True:\n",
    "            buffer = url.read(block_size)\n",
    "            if not buffer:\n",
    "                break\n",
    "\n",
    "            downloaded += len(buffer)\n",
    "            f.write(buffer)\n",
    "            status = ((\"[%-\" + str(status_width + 1) + \"s] %3.2f%%\") %\n",
    "              ('=' * int(downloaded / filesize * status_width) + '>', downloaded * 100 / filesize))\n",
    "            display.clear_output(wait=True)\n",
    "            print(status, end='')\n",
    "\n",
    "    with zipfile.ZipFile(filename) as zf:\n",
    "        print('\\nExtracting %s ...' % filename)\n",
    "        zf.extractall(SavePath)\n",
    "        print('Done.')\n",
    "\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_names = []\n",
    "file_tags = []\n",
    "with open(SavePath + 'list_attr_celeba.txt') as f:\n",
    "    data_size = int(f.readline())\n",
    "    tag_list = np.array(f.readline().split())\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        file_name, *tagging = line.split()\n",
    "        file_names.append(file_name)\n",
    "        file_tags.append((np.array(tagging).astype(int) == 1).astype(int))\n",
    "        \n",
    "    file_names = np.array(file_names)\n",
    "    file_tags = np.array(file_tags)\n",
    "    \n",
    "file_size = len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_load(name, width, height):\n",
    "    img = Image.open(SavePath + 'img_align_celeba/' + name)\n",
    "    img = img.resize((width, height), resample=Image.ANTIALIAS)\n",
    "    pixel = np.array([x for x in img.getdata()])\n",
    "    return pixel.reshape(width, height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_set = {}\n",
    "def batch_from_dataset(names, width, height):\n",
    "    batch = []\n",
    "    for name in names:\n",
    "        if name not in loaded_set:\n",
    "            loaded_set[name] = image_load(name, width, height)\n",
    "        batch.append(loaded_set[name])\n",
    "        \n",
    "    return np.array(batch) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Function Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reference : https://github.com/GunhoChoi/LSGAN_TF/blob/master/LSGAN/LSGAN_TF.ipynb\n",
    "def LeakyReLU(x, leak=0.2, name='LeakyReLU'):\n",
    "    with tf.variable_scope(name):\n",
    "        f1 = 0.5 * (1 + leak)\n",
    "        f2 = 0.5 * (1 - leak)\n",
    "        return f1 * x + f2 * abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LinearUnit(x, name='Linear'):\n",
    "    with tf.variable_scope(name):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected_layer(x, output_size, initializer=tf.truncated_normal_initializer(stddev=2e-2), activation=tf.nn.relu, batch_normalization=None, name=''):\n",
    "    w = tf.get_variable(name + '_weight', [x.get_shape()[1], output_size], initializer=initializer)\n",
    "    b = tf.get_variable(name + '_bias', [output_size], initializer=initializer, dtype=tf.float32)\n",
    "    \n",
    "    l = tf.nn.bias_add(tf.matmul(x, w), b, name=name + '_layer')\n",
    "    \n",
    "    if batch_normalization != None:\n",
    "        l = tf.layers.batch_normalization(l, **batch_normalization, name=name + '_batch_norm')\n",
    "    \n",
    "    return activation(l, name=name + '_' + activation.__name__), l, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_2d(x, kernel_size, stride_size=[1, 1, 1, 1], padding='SAME', initializer=tf.truncated_normal_initializer(stddev=2e-2), activation=tf.nn.relu, batch_normalization=None, name=''):\n",
    "    if type(kernel_size) == tuple: kernel_size = list(kernel_size)\n",
    "    if kernel_size[2] == -1: kernel_size[2] = int(x.get_shape()[-1])\n",
    "\n",
    "    w = tf.get_variable(name + '_weight', kernel_size, initializer=initializer)\n",
    "    b = tf.get_variable(name + '_bias', kernel_size[-1], initializer=initializer)\n",
    "    c = tf.nn.conv2d(x, w, strides=stride_size, padding=padding)\n",
    "    \n",
    "    l = tf.nn.bias_add(c, b, name=name + '_layer')\n",
    "    \n",
    "    if batch_normalization != None:\n",
    "        l = tf.layers.batch_normalization(l, **batch_normalization, name=name + '_batch_norm')\n",
    "    \n",
    "    return activation(l, name=name + '_' + activation.__name__), l, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv_2d(x, kernel_size, output_shape, stride_size=[1, 1, 1, 1], padding='SAME', initializer=tf.random_normal_initializer(stddev=2e-2), activation=tf.nn.relu, batch_normalization=None, name=''):\n",
    "    if type(kernel_size) == tuple: kernel_size = list(kernel_size)\n",
    "    if kernel_size[2] == -1: kernel_size[2] = output_shape[-1]\n",
    "    if kernel_size[3] == -1: kernel_size[3] = int(x.get_shape()[-1])\n",
    "    \n",
    "    if type(output_shape) == tuple: output_shape = list(output_shape)\n",
    "    if output_shape[0] == -1: output_shape[0] = tf.shape(x)[0]\n",
    "    \n",
    "    w = tf.get_variable(name + '_weight', kernel_size, initializer=initializer)\n",
    "    b = tf.get_variable(name + '_bias', kernel_size[-2], initializer=initializer)\n",
    "    c = tf.nn.conv2d_transpose(x, w, output_shape=output_shape, strides=stride_size, padding=padding)\n",
    "    \n",
    "    l = tf.nn.bias_add(c, b, name=name + '_layer')\n",
    "    \n",
    "    if batch_normalization != None:\n",
    "        l = tf.layers.batch_normalization(l, **batch_normalization, name=name + '_batch_norm')\n",
    "    \n",
    "    return activation(l, name=name + '_' + activation.__name__), l, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _batch_norm(x, params, name=''):\n",
    "    return tf.layers.batch_normalization(x, **params, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _activation(x, activation, name=''):\n",
    "    return activation(x, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Maker Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelMaker(object):\n",
    "    def __init__(self, layers_shape):\n",
    "        self.layers_shape = layers_shape\n",
    "        \n",
    "    def __call__(self, x, name, dropout_list=None, reuse=False):\n",
    "        parameters = set()\n",
    "        layers = set()\n",
    "        \n",
    "        last_layer = x\n",
    "        \n",
    "        dropout = None\n",
    "                \n",
    "        # scope set\n",
    "        with tf.variable_scope(name, reuse=reuse) as scope:\n",
    "            # create layers\n",
    "            for i, (layer_type, *layer_shape) in enumerate(self.layers_shape):\n",
    "                \n",
    "                '''\n",
    "                create matching layer\n",
    "                \n",
    "                c2l  : Convolutional 2 Dimention Layer\n",
    "                dc2l : Deconvolutional 2 Dimention Layer\n",
    "                fcl  : Fully Connected Layer(Dense) Layer\n",
    "                mpl  : Max Pooling Layer\n",
    "                rs   : Reshape\n",
    "                flat : Flatten\n",
    "                bn   : Batch Normalization\n",
    "                activation : Activation\n",
    "                '''\n",
    "                if layer_type == 'c2l': # Convolutional 2D Layer\n",
    "                    kernel_shape, stride_shape, dropout, params = layer_shape\n",
    "                    \n",
    "                    last_layer, l, w, b = conv_2d(x=last_layer, \\\n",
    "                                            kernel_size=kernel_shape, stride_size=stride_shape, \\\n",
    "                                            name=str(i) + '_c2', **params)\n",
    "                    \n",
    "                    parameters.add(w)\n",
    "                    parameters.add(b)\n",
    "                    layers.add(last_layer)\n",
    "                    layers.add(l)\n",
    "                    \n",
    "                elif layer_type == 'dc2l': # Deconvolutional 2D Layer\n",
    "                    kernel_shape, output_shape, stride_shape, dropout, params = layer_shape\n",
    "                    \n",
    "                    last_layer, l, w, b = deconv_2d(x=last_layer, output_shape=output_shape, \\\n",
    "                                            kernel_size=kernel_shape, stride_size=stride_shape, \\\n",
    "                                            name=str(i) + '_c2', **params)\n",
    "                    \n",
    "                    parameters.add(w)\n",
    "                    parameters.add(b)\n",
    "                    layers.add(last_layer)\n",
    "                    layers.add(l)\n",
    "                    \n",
    "                elif layer_type == 'fcl': # Fully Connected Layer\n",
    "                    output_shape, dropout, params = layer_shape\n",
    "                    \n",
    "                    last_layer, l, w, b = fully_connected_layer(x=last_layer, \\\n",
    "                                                output_size=output_shape, name=str(i) + '_fc', **params)\n",
    "                    \n",
    "                    parameters.add(w)\n",
    "                    parameters.add(b)\n",
    "                    layers.add(last_layer)\n",
    "                    layers.add(l)\n",
    "                    \n",
    "                elif layer_type == 'mpl': # Max Pooling Layer\n",
    "                    kernel_shape, stride_shape, dropout, params = layer_shape\n",
    "                    \n",
    "                    last_layer = tf.nn.max_pool(input=x, ksize=kernel_shape, strides=stride_shape, \\\n",
    "                                    name=str(i) + '_mp_layer', **parmas)\n",
    "                    \n",
    "                    layers.add(last_layer)\n",
    "                    \n",
    "                elif layer_type == 'rs': # Reshape Layer\n",
    "                    reshape = layer_shape[0]\n",
    "                    last_layer = tf.reshape(last_layer, reshape, name=str(i) + '_reshape')\n",
    "                    \n",
    "                    layers.add(last_layer)\n",
    "                    \n",
    "                elif layer_type == 'flat': # Flat\n",
    "                    try:\n",
    "                        flat_size = int(np.prod(last_layer.get_shape()[1:]))\n",
    "                    except:\n",
    "                        flat_size = tf.reduce_prod(tf.shape(last_layer)[1:])\n",
    "                        \n",
    "                    last_layer = tf.reshape(last_layer, (-1, flat_size), name=str(i) + '_flat')\n",
    "                    \n",
    "                    layers.add(last_layer)\n",
    "                elif layer_type == 'bn':\n",
    "                    params = layer_shape[0]\n",
    "                    last_layer = _batch_norm(last_layer, params, name=str(i) + '_batch_norm')\n",
    "                    \n",
    "                    layers.add(last_layer)\n",
    "                    \n",
    "                elif layer_type == 'activation':\n",
    "                    activation = layer_shape[0]\n",
    "                    last_layer = _activation(last_layer, activation, name=str(i) + '_' + activation.__name__)\n",
    "                    \n",
    "                    layers.add(last_layer)\n",
    "                    \n",
    "                # Dropout Layer\n",
    "                if type(dropout) == int: # var is index\n",
    "                    last_layer = tf.nn.dropout(last_layer, dropout_list[dropout], name=str(i) + '_dropout')\n",
    "                    layers.add(last_layer)\n",
    "                elif type(dropout) == float: # var is constant value\n",
    "                    last_layer = tf.nn.dropout(last_layer, dropout, name=str(i) + '_dropout')\n",
    "                    layers.add(last_layer)\n",
    "                    \n",
    "                \n",
    "                # initialize vars\n",
    "                layer_shape = \\\n",
    "                kernel_shape = \\\n",
    "                stride_shape = \\\n",
    "                dropout = \\\n",
    "                params = None\n",
    "                    \n",
    "            return last_layer, layers, parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Util Function Implment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ArrayToImage(arr):\n",
    "    img = Image.fromarray(np.uint8(arr))\n",
    "    return img\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import time\n",
    "\n",
    "# image list display function for 'Jupytor notebook'\n",
    "def DisplayHorizontal(images, header=None, width=\"100%\", figsize=(20, 20), fontsize=20, depth=1):\n",
    "    num_images = len(images)\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for i in range(num_images):\n",
    "        image = images[i]\n",
    "        \n",
    "        fig.add_subplot(depth, num_images/depth, i+1)\n",
    "        plt.axis('off')\n",
    "        if header != None:\n",
    "            plt.title(header[i], fontsize=fontsize)\n",
    "        plt.imshow(image, cmap='Greys_r', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_size = len(tag_list)\n",
    "image_width = 64\n",
    "image_height = 64\n",
    "image_depth = 3\n",
    "image_size = image_width * image_height * image_depth\n",
    "\n",
    "# z: latent random variable\n",
    "z_var = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_depth = 5\n",
    "dis_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 shape: (64, 64)\n",
      "2 shape: (32, 32)\n",
      "3 shape: (16, 16)\n",
      "4 shape: (8, 8)\n",
      "5 shape: (4, 4)\n"
     ]
    }
   ],
   "source": [
    "for i in range(np.max((gen_depth, dis_depth))):\n",
    "    print('%d shape: (%d, %d)' % \\\n",
    "        (i+1, np.ceil(image_height / 2**i).astype(int), np.ceil(image_width / 2**i).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator_layer_shape=(    \n",
    "    ('fcl', 4*4*512, None, {'activation': LinearUnit},),\n",
    "    ('rs', (-1, 4, 4, 512),),\n",
    "    ('bn', {'momentum': 9e-1, 'epsilon': 1e-5, 'training': True},),\n",
    "    ('activation', tf.nn.relu,),\n",
    "    ('dc2l', (5, 5, -1, -1), (-1, 8, 8, 256), (1, 2, 2, 1), None, {'batch_normalization': {'momentum': 9e-1, 'epsilon': 1e-5, 'training': True}, 'padding': 'SAME', 'activation': tf.nn.relu},),\n",
    "    ('dc2l', (5, 5, -1, -1), (-1, 16, 16, 128), (1, 2, 2, 1), None, {'batch_normalization': {'momentum': 9e-1, 'epsilon': 1e-5, 'training': True}, 'padding': 'SAME', 'activation': tf.nn.relu},),\n",
    "    ('dc2l', (5, 5, -1, -1), (-1, 32, 32, 64), (1, 2, 2, 1), None, {'batch_normalization': {'momentum': 9e-1, 'epsilon': 1e-5, 'training': True}, 'padding': 'SAME', 'activation': tf.nn.relu},),\n",
    "    ('dc2l', (5, 5, -1, -1), (-1, 64, 64, 3), (1, 2, 2, 1), None, {'padding': 'SAME', 'activation': tf.nn.tanh},),\n",
    ")\n",
    "\n",
    "discriminator_layer_shape=(\n",
    "    ('c2l', (5, 5, -1, 64), (1, 2, 2, 1), None, {'padding': 'SAME', 'activation': LeakyReLU},),\n",
    "    ('c2l', (5, 5, -1, 128), (1, 2, 2, 1), None, {'batch_normalization': {'momentum': 9e-1, 'epsilon': 1e-5, 'training': True}, 'padding': 'SAME', 'activation': LeakyReLU},),\n",
    "    ('c2l', (5, 5, -1, 256), (1, 2, 2, 1), None, {'batch_normalization': {'momentum': 9e-1, 'epsilon': 1e-5, 'training': True}, 'padding': 'SAME', 'activation': LeakyReLU},),\n",
    "    ('c2l', (5, 5, -1, 512), (1, 2, 2, 1), None, {'batch_normalization': {'momentum': 9e-1, 'epsilon': 1e-5, 'training': True}, 'padding': 'SAME', 'activation': LeakyReLU},),\n",
    "    ('rs', (-1, 4 * 4 * 512),),\n",
    "    #('fcl', 1, None, {'activation': tf.nn.sigmoid})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 2e-4\n",
    "beta1=5e-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maker Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_Maker = ModelMaker(generator_layer_shape)\n",
    "D_Maker = ModelMaker(discriminator_layer_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PlaceHolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:%d' % gpu_num):\n",
    "    # Latent Random Variable\n",
    "    Z = tf.placeholder(tf.float32, [None, z_var])\n",
    "\n",
    "    # Generator\n",
    "    X_Fake, G_Layers, G_Params = G_Maker(Z, name='generator')\n",
    "\n",
    "    # For Real Data\n",
    "    X_Real = tf.placeholder(tf.float32, [None, image_height, image_width, image_depth])\n",
    "    \n",
    "    # Discriminator for Fake Data\n",
    "    FC_Fake, D_Fake_Layers, D_Params = D_Maker(X_Fake, name='discriminator')\n",
    "    # Discriminator for Real Data\n",
    "    FC_Real, D_Real_Layers, _ = D_Maker(X_Real, name='discriminator', reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:%d' % gpu_num):\n",
    "    # Fake Outputs\n",
    "    with tf.variable_scope('discriminator'):\n",
    "        Fake, Fake_Logits, *_ = fully_connected_layer(FC_Fake, 1, activation=tf.nn.sigmoid, name='prob')\n",
    "\n",
    "    # Real Outputs\n",
    "    with tf.variable_scope('discriminator', reuse=True):\n",
    "        Real, Real_Logits, *_ = fully_connected_layer(FC_Real, 1, activation=tf.nn.sigmoid, name='prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:%d' % gpu_num):\n",
    "    Optimizer_D = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "    Optimizer_G = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
    "\n",
    "    Loss_D = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Real_Logits, labels=tf.ones_like(Real)) + \\\n",
    "                            tf.nn.sigmoid_cross_entropy_with_logits(logits=Fake_Logits, labels=tf.zeros_like(Fake)))\n",
    "    Loss_G = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Fake_Logits, labels=tf.ones_like(Fake)))\n",
    "    \n",
    "    Train_D = Optimizer_D.minimize(Loss_D, var_list=D_Params)\n",
    "    Train_G = Optimizer_G.minimize(Loss_G, var_list=G_Params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch_size = 15\n",
    "batch_size = 512\n",
    "train_d_count, train_g_count = 1, 2\n",
    "\n",
    "count = np.ceil(len(file_names) / batch_size).astype(int)\n",
    "\n",
    "display_count = int(count/5)\n",
    "display_with = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_sample = np.random.uniform(-1, 1, size=(100, z_var)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.8, allow_growth=True)))\n",
    "saver = tf.train.Saver()\n",
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('result/'):\n",
    "    os.mkdir('result/')\n",
    "if not os.path.exists('result/figures/'):\n",
    "    os.mkdir('result/figures/')\n",
    "if not os.path.exists('result/model/'):\n",
    "    os.mkdir('result/model/')\n",
    "    \n",
    "    \n",
    "sample_figure_path = 'result/figures/'\n",
    "model_path = 'result/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 [=>                   ] 13312/202599, loss: d=1.3804, g=0.0855"
     ]
    }
   ],
   "source": [
    "while epoch < epoch_size:\n",
    "    d_loss = []\n",
    "    g_loss = []\n",
    "    \n",
    "    batch_count = 0    \n",
    "    status = ('start training')\n",
    "    sys.stdout.write(status)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "    shuffle_files = file_names[np.random.permutation(range(len(file_names)))]\n",
    "    for i in range(count):\n",
    "        s = i * batch_size\n",
    "        e = s + batch_size\n",
    "        \n",
    "        batch_files = shuffle_files[s:e]\n",
    "        batch_train = batch_from_dataset(batch_files, image_width, image_height)\n",
    "        batch_train = batch_train.astype(np.float32) * 2 - 1\n",
    "        batch_count += len(batch_train)\n",
    "        \n",
    "        batch_z = np.random.uniform(-1, 1, size=(len(batch_train), z_var)).astype(np.float32)\n",
    "        \n",
    "        # Discriminator Train\n",
    "        for _ in range(train_d_count):\n",
    "            _, loss_d = sess.run([Train_D, Loss_D], feed_dict={X_Real: batch_train, Z: batch_z})\n",
    "            d_loss += [loss_d]\n",
    "        \n",
    "        # Generator Train\n",
    "        for _ in range(train_g_count):\n",
    "            _, loss_g = sess.run([Train_G, Loss_G], feed_dict={Z: batch_z})\n",
    "            g_loss += [loss_g]\n",
    "                        \n",
    "        if (i+1) % display_count == 0:\n",
    "            gen_mnist = sess.run(X_Fake, feed_dict={Z: z_sample})\n",
    "\n",
    "            display.clear_output(wait=True)\n",
    "            DisplayHorizontal([ArrayToImage((x * 0.5 + 0.5) * 255) for x in gen_mnist], depth=10, figsize=(16, 16))\n",
    "            print('Epoch: %d, Count: %d' % (epoch+1, i+1))\n",
    "            display.display(plt.gcf())\n",
    "            plt.savefig(sample_figure_path + 'DCGAN_epoch_%d_batch_%d.png' % (epoch+1, i+1))\n",
    "            plt.close()\n",
    "        else:\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.flush()\n",
    "        status = ((\"Epoch: %d [%-\" + str(display_with + 1) + \"s] %d/%d, loss: d=%.4f, g=%.4f\") %\n",
    "          (epoch+1, '=' * int(batch_count / file_size * display_with) + '>', batch_count, file_size, np.mean(loss_d), np.mean(loss_g)))\n",
    "        sys.stdout.write(status)\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    saver.save(sess, model_path + 'DCGAN_CelebA.ckpt')\n",
    "    \n",
    "    epoch += 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

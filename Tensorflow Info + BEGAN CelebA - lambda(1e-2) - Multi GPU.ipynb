{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CelebA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* site : http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download & Load CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SavePath = 'CelebA_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(SavePath):\n",
    "    # Dropbox Link can be terminated\n",
    "    link = 'https://www.dropbox.com/s/gxjc9p7s6xmo09k/CelebA_Align.zip?dl=1'\n",
    "    url = urllib.request.urlopen(link)\n",
    "\n",
    "    filesize = int(url.headers['Content-Length'])\n",
    "    filename = 'CelebA_Align.zip'\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        downloaded = 0\n",
    "        block_size = 8192\n",
    "        status_width = 70\n",
    "        while True:\n",
    "            buffer = url.read(block_size)\n",
    "            if not buffer:\n",
    "                break\n",
    "\n",
    "            downloaded += len(buffer)\n",
    "            f.write(buffer)\n",
    "            status = ((\"[%-\" + str(status_width + 1) + \"s] %3.2f%%\") %\n",
    "              ('=' * int(downloaded / filesize * status_width) + '>', downloaded * 100 / filesize))\n",
    "            display.clear_output(wait=True)\n",
    "            print(status, end='')\n",
    "\n",
    "    with zipfile.ZipFile(filename) as zf:\n",
    "        print('\\nExtracting %s ...' % filename)\n",
    "        zf.extractall(SavePath)\n",
    "        print('Done.')\n",
    "\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_names = []\n",
    "file_tags = []\n",
    "with open(SavePath + 'list_attr_celeba.txt') as f:\n",
    "    data_size = int(f.readline())\n",
    "    tag_list = np.array(f.readline().split())\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        file_name, *tagging = line.split()\n",
    "        file_names.append(file_name)\n",
    "        file_tags.append((np.array(tagging).astype(int) == 1).astype(int))\n",
    "        \n",
    "    file_names = np.array(file_names)\n",
    "    file_tags = np.array(file_tags)\n",
    "    \n",
    "file_size = len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_load(name, width, height):\n",
    "    img = Image.open(SavePath + 'img_align_celeba/' + name)\n",
    "    img = img.resize((width, height), resample=Image.ANTIALIAS)\n",
    "    pixel = np.array([x for x in img.getdata()])\n",
    "    return pixel.reshape(width, height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_set = {}\n",
    "def batch_from_dataset(names, width, height):\n",
    "    batch = []\n",
    "    for name in names:\n",
    "        if name not in loaded_set:\n",
    "            loaded_set[name] = image_load(name, width, height)\n",
    "        batch.append(loaded_set[name])\n",
    "        \n",
    "    return np.array(batch) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Function Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reference : https://github.com/GunhoChoi/LSGAN_TF/blob/master/LSGAN/LSGAN_TF.ipynb\n",
    "def LeakyReLU(x, leak=0.2, name='LeakyReLU'):\n",
    "    with tf.variable_scope(name):\n",
    "        f1 = 0.5 * (1 + leak)\n",
    "        f2 = 0.5 * (1 - leak)\n",
    "        return f1 * x + f2 * abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LinearUnit(x, name='Linear'):\n",
    "    with tf.variable_scope(name):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected_layer(x, output_size, initializer=tf.truncated_normal_initializer(stddev=2e-2), activation=tf.nn.relu, batch_normalization=None, name=''):\n",
    "    w = tf.get_variable(name + '_weight', [x.get_shape()[1], output_size], initializer=initializer)\n",
    "    b = tf.get_variable(name + '_bias', [output_size], initializer=initializer, dtype=tf.float32)\n",
    "    \n",
    "    l = tf.nn.bias_add(tf.matmul(x, w), b, name=name + '_layer')\n",
    "    \n",
    "    if batch_normalization != None:\n",
    "        l = tf.layers.batch_normalization(l, **batch_normalization, name=name + '_batch_norm')\n",
    "    \n",
    "    return activation(l, name=name + '_' + activation.__name__), l, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_2d(x, kernel_size, stride_size=[1, 1, 1, 1], padding='SAME', initializer=tf.truncated_normal_initializer(stddev=2e-2), activation=tf.nn.relu, batch_normalization=None, name=''):\n",
    "    if type(kernel_size) == tuple: kernel_size = list(kernel_size)\n",
    "    if kernel_size[2] == -1: kernel_size[2] = int(x.get_shape()[-1])\n",
    "\n",
    "    w = tf.get_variable(name + '_weight', kernel_size, initializer=initializer)\n",
    "    b = tf.get_variable(name + '_bias', kernel_size[-1], initializer=initializer)\n",
    "    c = tf.nn.conv2d(x, w, strides=stride_size, padding=padding)\n",
    "    \n",
    "    l = tf.nn.bias_add(c, b, name=name + '_layer')\n",
    "    \n",
    "    if batch_normalization != None:\n",
    "        l = tf.layers.batch_normalization(l, **batch_normalization, name=name + '_batch_norm')\n",
    "    \n",
    "    return activation(l, name=name + '_' + activation.__name__), l, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv_2d(x, kernel_size, output_shape, stride_size=[1, 1, 1, 1], padding='SAME', initializer=tf.random_normal_initializer(stddev=2e-2), activation=tf.nn.relu, batch_normalization=None, name=''):\n",
    "    if type(kernel_size) == tuple: kernel_size = list(kernel_size)\n",
    "    if kernel_size[2] == -1: kernel_size[2] = output_shape[-1]\n",
    "    if kernel_size[3] == -1: kernel_size[3] = int(x.get_shape()[-1])\n",
    "    \n",
    "    if type(output_shape) == tuple: output_shape = list(output_shape)\n",
    "    if output_shape[0] == -1: output_shape[0] = tf.shape(x)[0]\n",
    "    \n",
    "    w = tf.get_variable(name + '_weight', kernel_size, initializer=initializer)\n",
    "    b = tf.get_variable(name + '_bias', kernel_size[-2], initializer=initializer)\n",
    "    c = tf.nn.conv2d_transpose(x, w, output_shape=output_shape, strides=stride_size, padding=padding)\n",
    "    \n",
    "    l = tf.nn.bias_add(c, b, name=name + '_layer')\n",
    "    \n",
    "    if batch_normalization != None:\n",
    "        l = tf.layers.batch_normalization(l, **batch_normalization, name=name + '_batch_norm')\n",
    "    \n",
    "    return activation(l, name=name + '_' + activation.__name__), l, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _scale(x, width, height, params, name=''):\n",
    "    return tf.image.resize_nearest_neighbor(x, (width, height), **params, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _batch_norm(x, params, name=''):\n",
    "    return tf.layers.batch_normalization(x, **params, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _activation(x, activation, name=''):\n",
    "    return activation(x, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Maker Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelMaker(object):\n",
    "    def __init__(self, layers_shape):\n",
    "        self.layers_shape = layers_shape\n",
    "        \n",
    "    def __call__(self, x, name, dropout_list=None, reuse=False):\n",
    "        parameters = set()\n",
    "        layers = set()\n",
    "        \n",
    "        last_layer = x\n",
    "        \n",
    "        dropout = None\n",
    "                \n",
    "        # scope set\n",
    "        with tf.variable_scope(name, reuse=reuse) as scope:\n",
    "            # create layers\n",
    "            for i, (layer_type, *layer_shape) in enumerate(self.layers_shape):\n",
    "                \n",
    "                '''\n",
    "                create matching layer\n",
    "                \n",
    "                c2l  : Convolutional 2 Dimention Layer\n",
    "                dc2l : Deconvolutional 2 Dimention Layer\n",
    "                fcl  : Fully Connected Layer(Dense) Layer\n",
    "                mpl  : Max Pooling Layer\n",
    "                rs   : Reshape\n",
    "                flat : Flatten\n",
    "                bn   : Batch Normalization\n",
    "                activation : Activation\n",
    "                '''\n",
    "                if layer_type == 'c2l': # Convolutional 2D Layer\n",
    "                    kernel_shape, stride_shape, dropout, params = layer_shape\n",
    "                    \n",
    "                    last_layer, l, w, b = conv_2d(x=last_layer, \\\n",
    "                                            kernel_size=kernel_shape, stride_size=stride_shape, \\\n",
    "                                            name=str(i) + '_c2', **params)\n",
    "                    \n",
    "                    parameters.add(w)\n",
    "                    parameters.add(b)\n",
    "                    layers.add(last_layer)\n",
    "                    layers.add(l)\n",
    "                    \n",
    "                elif layer_type == 'dc2l': # Deconvolutional 2D Layer\n",
    "                    kernel_shape, output_shape, stride_shape, dropout, params = layer_shape\n",
    "                    \n",
    "                    last_layer, l, w, b = deconv_2d(x=last_layer, output_shape=output_shape, \\\n",
    "                                            kernel_size=kernel_shape, stride_size=stride_shape, \\\n",
    "                                            name=str(i) + '_c2', **params)\n",
    "                    \n",
    "                    parameters.add(w)\n",
    "                    parameters.add(b)\n",
    "                    layers.add(last_layer)\n",
    "                    layers.add(l)\n",
    "                    \n",
    "                elif layer_type == 'fcl': # Fully Connected Layer\n",
    "                    output_shape, dropout, params = layer_shape\n",
    "                    \n",
    "                    last_layer, l, w, b = fully_connected_layer(x=last_layer, \\\n",
    "                                                output_size=output_shape, name=str(i) + '_fc', **params)\n",
    "                    \n",
    "                    parameters.add(w)\n",
    "                    parameters.add(b)\n",
    "                    layers.add(last_layer)\n",
    "                    layers.add(l)\n",
    "                    \n",
    "                elif layer_type == 'mpl': # Max Pooling Layer\n",
    "                    kernel_shape, stride_shape, dropout, params = layer_shape\n",
    "                    \n",
    "                    last_layer = tf.nn.max_pool(input=x, ksize=kernel_shape, strides=stride_shape, \\\n",
    "                                    name=str(i) + '_mp_layer', **parmas)\n",
    "                    \n",
    "                    layers.add(last_layer)\n",
    "                    \n",
    "                elif layer_type == 'rs': # Reshape Layer\n",
    "                    reshape = layer_shape[0]\n",
    "                    last_layer = tf.reshape(last_layer, reshape, name=str(i) + '_reshape')\n",
    "                    \n",
    "                    layers.add(last_layer)\n",
    "                    \n",
    "                elif layer_type == 'flat': # Flat\n",
    "                    try:\n",
    "                        flat_size = int(np.prod(last_layer.get_shape()[1:]))\n",
    "                    except:\n",
    "                        flat_size = tf.reduce_prod(tf.shape(last_layer)[1:])\n",
    "                        \n",
    "                    last_layer = tf.reshape(last_layer, (-1, flat_size), name=str(i) + '_flat')\n",
    "                    \n",
    "                    layers.add(last_layer)\n",
    "                elif layer_type == 'scale':\n",
    "                    width, height, params = layer_shape\n",
    "                    last_layer = _scale(last_layer, width, height, params, name=str(i) + '_scale')\n",
    "                    \n",
    "                    layers.add(last_layer)\n",
    "                    \n",
    "                elif layer_type == 'bn':\n",
    "                    params = layer_shape[0]\n",
    "                    last_layer = _batch_norm(last_layer, params, name=str(i) + '_batch_norm')\n",
    "                    \n",
    "                    layers.add(last_layer)\n",
    "                    \n",
    "                elif layer_type == 'activation':\n",
    "                    activation = layer_shape[0]\n",
    "                    last_layer = _activation(last_layer, activation, name=str(i) + '_' + activation.__name__)\n",
    "                    \n",
    "                    layers.add(last_layer)\n",
    "                    \n",
    "                # Dropout Layer\n",
    "                if type(dropout) == int: # var is index\n",
    "                    last_layer = tf.nn.dropout(last_layer, dropout_list[dropout], name=str(i) + '_dropout')\n",
    "                    layers.add(last_layer)\n",
    "                elif type(dropout) == float: # var is constant value\n",
    "                    last_layer = tf.nn.dropout(last_layer, dropout, name=str(i) + '_dropout')\n",
    "                    layers.add(last_layer)\n",
    "                    \n",
    "                \n",
    "                # initialize vars\n",
    "                layer_shape = \\\n",
    "                kernel_shape = \\\n",
    "                stride_shape = \\\n",
    "                dropout = \\\n",
    "                params = None\n",
    "                    \n",
    "            return last_layer, list(layers), list(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Util Function Implment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ArrayToImage(arr):\n",
    "    img = Image.fromarray(np.uint8(arr))\n",
    "    return img\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import time\n",
    "\n",
    "# image list display function for 'Jupytor notebook'\n",
    "def DisplayHorizontal(images, header=None, width=\"100%\", figsize=(20, 20), fontsize=20, depth=1):\n",
    "    num_images = len(images)\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for i in range(num_images):\n",
    "        image = images[i]\n",
    "        \n",
    "        fig.add_subplot(depth, num_images/depth, i+1)\n",
    "        plt.axis('off')\n",
    "        if header != None:\n",
    "            plt.title(header[i], fontsize=fontsize)\n",
    "        plt.imshow(image, cmap='Greys_r', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def slerp(val, low, high):\n",
    "    \"\"\"Code from https://github.com/soumith/dcgan.torch/issues/14\"\"\"\n",
    "    omega = np.arccos(np.clip(np.dot(low/np.linalg.norm(low), high/np.linalg.norm(high)), -1, 1))\n",
    "    so = np.sin(omega)\n",
    "    if so == 0:\n",
    "        return (1.0-val) * low + val * high # L'Hopital's rule/LERP\n",
    "    return np.sin((1.0-val)*omega) / so * low + np.sin(val*omega) / so * high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_gradients(tower_grads):\n",
    "    \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "    Note that this function provides a synchronization point across all towers.\n",
    "    Args:\n",
    "    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n",
    "      is over individual gradients. The inner list is over the gradient\n",
    "      calculation for each tower.\n",
    "    Returns:\n",
    "     List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "     across all towers.\n",
    "     \n",
    "     \n",
    "    \"\"\"\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        # Note that each grad_and_vars looks like the following:\n",
    "        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(grads, axis=0)\n",
    "        grad = tf.reduce_mean(grad, axis=0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_size = len(tag_list)\n",
    "image_width = 64\n",
    "image_height = 64\n",
    "image_depth = 3\n",
    "image_size = image_width * image_height * image_depth\n",
    "\n",
    "# z: latent random variable\n",
    "z_var = 1000\n",
    "z_category = tag_size\n",
    "z = z_var + z_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generator_layer_shape=(    \n",
    "    ('fcl', 8*8*128, None, {'activation': LinearUnit},), # Dense Layer\n",
    "    ('rs', (-1, 8, 8, 128),), # Reshape\n",
    "        \n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('scale', 16, 16, {}), # Upscale    \n",
    "    \n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('scale', 32, 32, {}), # Upscale    \n",
    "    \n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('scale', 64, 64, {}), # Upscale    \n",
    "    \n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 3), (1, 1, 1, 1), None, {'activation': LinearUnit},),\n",
    ")\n",
    "\n",
    "encoder_layer_shape=(\n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    \n",
    "    # Encoder\n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 128), (1, 2, 2, 1), None, {'activation': tf.nn.elu},),\n",
    "    \n",
    "    ('c2l', (3, 3, -1, 256), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 256), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 256), (1, 2, 2, 1), None, {'activation': tf.nn.elu},),\n",
    "    \n",
    "    ('c2l', (3, 3, -1, 512), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 512), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 512), (1, 2, 2, 1), None, {'activation': tf.nn.elu},),\n",
    "    \n",
    "    ('c2l', (3, 3, -1, 1024), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 1024), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    \n",
    "    ('rs', (-1, 8 * 8 * 1024)),\n",
    "    ('fcl', z, None, {'activation': LinearUnit},),\n",
    ")\n",
    "\n",
    "decoder_layer_shape=(\n",
    "    # Decoder\n",
    "    ('fcl', 8 * 8 * 128, None, {'activation': LinearUnit},),\n",
    "    ('rs', (-1, 8, 8, 128)),\n",
    "        \n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('scale', 16, 16, {}), # Upscale    \n",
    "    \n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('scale', 32, 32, {}), # Upscale    \n",
    "    \n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('scale', 64, 64, {}), # Upscale    \n",
    "    \n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 128), (1, 1, 1, 1), None, {'activation': tf.nn.elu},),\n",
    "    ('c2l', (3, 3, -1, 3), (1, 1, 1, 1), None, {'activation': LinearUnit},),\n",
    "    \n",
    "    #('fcl', 1, None, {'activation': tf.nn.sigmoid})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "beta1=5e-1\n",
    "\n",
    "lambda_info = 1e-2\n",
    "\n",
    "gamma = 5e-1\n",
    "lambda_k = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maker Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_Maker = ModelMaker(generator_layer_shape)\n",
    "E_Maker = ModelMaker(encoder_layer_shape)\n",
    "D_Maker = ModelMaker(decoder_layer_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PlaceHolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_num = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with Graph.as_default():\n",
    "    Global_Step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z_var_list = []\n",
    "z_category_list = []\n",
    "z_list = []\n",
    "\n",
    "x_fake_list = []\n",
    "generator_layers_list = []\n",
    "x_real_list = []\n",
    "y_list = []\n",
    "\n",
    "encode_fake_list = []\n",
    "encode_fake_layers_list = []\n",
    "encode_real_list = []\n",
    "encode_real_layers_list = []\n",
    "decode_fake_list = []\n",
    "decode_fake_layers_list = []\n",
    "decode_real_list = []\n",
    "decode_real_layers_list = []\n",
    "\n",
    "with Graph.as_default():\n",
    "    for i in range(len(gpu_num)):\n",
    "        with tf.device('/gpu:%d' % gpu_num[i]):\n",
    "            with tf.name_scope('Tower_%d' % i) as name_scope:\n",
    "                reuse = True if i != 0 else False   \n",
    "\n",
    "                # Latent Random Variable\n",
    "                Z_var = tf.placeholder(tf.float32, [None, z_var])\n",
    "                z_var_list.append(Z_var)\n",
    "                # Data Label Information\n",
    "                Z_category = tf.placeholder(tf.float32, [None, z_category])\n",
    "                z_category_list.append(Z_category)\n",
    "\n",
    "                Z = tf.concat([Z_var, Z_category], axis=1)\n",
    "                z_list.append(Z)\n",
    "\n",
    "\n",
    "                # Generator\n",
    "                X_Fake, G_Layers, G_Params = G_Maker(Z, name='generator', reuse=reuse)\n",
    "                x_fake_list.append(X_Fake)\n",
    "                generator_layers_list.append(G_Layers)\n",
    "\n",
    "                # For Real Data\n",
    "                X_Real = tf.placeholder(tf.float32, [None, image_height, image_width, image_depth])\n",
    "                x_real_list.append(X_Real)\n",
    "                Y = tf.placeholder(tf.float32, shape=[None, z_category])\n",
    "                y_list.append(Y)\n",
    "\n",
    "                # Encoder for Fake Data\n",
    "                E_Fake, E_Fake_Layers, E_Params = E_Maker(X_Fake, name='encoder', reuse=reuse)\n",
    "                encode_fake_list.append(E_Fake)\n",
    "                encode_fake_layers_list.append(E_Fake_Layers)\n",
    "                # Encoder for Real Data\n",
    "                E_Real, E_Real_Layers, _ = E_Maker(X_Real, name='encoder', reuse=True)\n",
    "                encode_real_list.append(E_Real)\n",
    "                encode_real_layers_list.append(E_Real_Layers)\n",
    "\n",
    "                # Decoder for Fake Data\n",
    "                D_Fake, D_Fake_Layers, D_Params = D_Maker(E_Fake, name='decoder', reuse=reuse)\n",
    "                decode_fake_list.append(D_Fake)\n",
    "                decode_fake_layers_list.append(D_Fake_Layers)\n",
    "                # Decoder for Real Data\n",
    "                D_Real, D_Real_Layers, _ = D_Maker(E_Real, name='decoder', reuse=True)\n",
    "                decode_real_list.append(D_Real)\n",
    "                decode_real_layers_list.append(D_Real_Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AE_Params = list(E_Params) + list(D_Params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Category Layer with Encode Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fake_category_list = []\n",
    "real_category_list = []\n",
    "\n",
    "with Graph.as_default():\n",
    "    for i in range(len(gpu_num)):\n",
    "        with tf.device('/gpu:%d' % gpu_num[i]):\n",
    "            with tf.name_scope('Tower_%d' % i) as name_scope:\n",
    "                reuse = True if i != 0 else False   \n",
    "\n",
    "                # Fake Category\n",
    "                with tf.variable_scope('category', reuse=reuse):\n",
    "                    Fake_Category, *_ = fully_connected_layer(\\\n",
    "                                                    encode_fake_list[i],\n",
    "                                                    z_category, activation=tf.nn.sigmoid, \n",
    "                                                    name='label')\n",
    "                    fake_category_list.append(Fake_Category)\n",
    "\n",
    "                with tf.variable_scope('category', reuse=True):\n",
    "                    Real_Category, *_ = fully_connected_layer(\\\n",
    "                                                    encode_real_list[i], \n",
    "                                                    z_category, activation=tf.nn.sigmoid, \n",
    "                                                    name='label')\n",
    "                    real_category_list.append(Real_Category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with Graph.as_default():\n",
    "    LR = tf.Variable(learning_rate, name='learning_rate')\n",
    "    LR_Update = tf.assign(LR, tf.maximum(LR * 0.5, 2e-5))\n",
    "\n",
    "    Optimizer_D = tf.train.AdamOptimizer(learning_rate=LR)\n",
    "    Optimizer_G = tf.train.AdamOptimizer(learning_rate=LR)\n",
    "\n",
    "    K = tf.get_variable('K', [], initializer=tf.constant_initializer(.0), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_fake_list = []\n",
    "loss_real_list = []\n",
    "loss_fake_category_list = []\n",
    "loss_real_category_list = []\n",
    "\n",
    "loss_g_list = []\n",
    "loss_d_list = []\n",
    "\n",
    "grads_d_list = []\n",
    "grads_g_list = []\n",
    "\n",
    "with Graph.as_default():\n",
    "    for i in range(len(gpu_num)):\n",
    "        with tf.device('/gpu:%d' % gpu_num[i]):\n",
    "            with tf.name_scope('Tower_%d' % i) as name_scope:\n",
    "                reuse = True if i != 0 else False\n",
    "\n",
    "                Loss_D_Fake = tf.reduce_mean(tf.abs(decode_fake_list[i] - x_fake_list[i]))\n",
    "                loss_fake_list.append(Loss_D_Fake)\n",
    "                Loss_D_Real = tf.reduce_mean(tf.abs(decode_real_list[i] - x_real_list[i]))\n",
    "                loss_real_list.append(Loss_D_Real)\n",
    "\n",
    "\n",
    "                Loss_D_Fake_Category = tf.reduce_mean(tf.losses.softmax_cross_entropy(\\\n",
    "                                                        onehot_labels=z_category_list[i], logits=fake_category_list[i]))\n",
    "                loss_real_category_list.append(Loss_D_Fake_Category)\n",
    "                Loss_D_Real_Category = tf.reduce_mean(tf.losses.softmax_cross_entropy(\\\n",
    "                                                        onehot_labels=y_list[i], logits=real_category_list[i]))\n",
    "                loss_fake_category_list.append(Loss_D_Real_Category)\n",
    "\n",
    "\n",
    "                Loss_D = Loss_D_Real - K * Loss_D_Fake + lambda_info * Loss_D_Real_Category\n",
    "                loss_d_list.append(Loss_D)\n",
    "                Loss_G = Loss_D_Fake + lambda_info * Loss_D_Fake_Category\n",
    "                loss_g_list.append(Loss_G)\n",
    "\n",
    "                Grad_D = Optimizer_D.compute_gradients(Loss_D, var_list=AE_Params)\n",
    "                grads_d_list.append(Grad_D)\n",
    "                Grad_G = Optimizer_G.compute_gradients(Loss_G, var_list=G_Params)\n",
    "                grads_g_list.append(Grad_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with Graph.as_default():\n",
    "    Grads_D = average_gradients(grads_d_list)\n",
    "    Grads_G = average_gradients(grads_g_list)\n",
    "\n",
    "    Train_D = Optimizer_D.apply_gradients(Grads_D, global_step=Global_Step)\n",
    "    Train_G = Optimizer_G.apply_gradients(Grads_G, global_step=Global_Step)\n",
    "\n",
    "    Loss_D = tf.reduce_mean(loss_d_list)\n",
    "    Loss_G = tf.reduce_mean(loss_g_list)\n",
    "\n",
    "    with tf.control_dependencies((Train_D, Train_G)):\n",
    "        Balance = gamma * Loss_D - Loss_G\n",
    "\n",
    "        K_Update = tf.assign(K, tf.clip_by_value(K + lambda_k * Balance, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch_size = 50\n",
    "batch_size = 16\n",
    "\n",
    "count = np.floor(len(file_names) / (batch_size * len(gpu_num))).astype(int)\n",
    "\n",
    "display_count = int(count/5)\n",
    "display_with = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_size = 10\n",
    "image_sample = batch_from_dataset(file_names[:sample_size], image_width, image_height)\n",
    "image_sample = image_sample * 2 - 1\n",
    "z_var_sample = np.random.uniform(-1, 1, size=(sample_size, z_var)).astype(np.float32)\n",
    "z_category_sample = np.random.randint(0, 2, size=(sample_size, z_category))\n",
    "z_sample = np.concatenate((z_var_sample, z_category_sample), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GPUOps = tf.GPUOptions(\n",
    "            allow_growth=True, \n",
    "            per_process_gpu_memory_fraction=0.8\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(graph=Graph, config=tf.ConfigProto(\n",
    "                                                    gpu_options = GPUOps,\n",
    "                                                    log_device_placement=True,\n",
    "                                                    allow_soft_placement=True))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "tf.global_variables_initializer().run(session=sess)\n",
    "tf.local_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('result/'):\n",
    "    os.mkdir('result/')\n",
    "if not os.path.exists('result/figures/'):\n",
    "    os.mkdir('result/figures/')\n",
    "if not os.path.exists('result/figures/info_BEGAN'):\n",
    "    os.mkdir('result/figures/info_BEGAN')\n",
    "if not os.path.exists('result/model/'):\n",
    "    os.mkdir('result/model/')\n",
    "if not os.path.exists('result/model/info_BEGAN'):\n",
    "    os.mkdir('result/model/info_BEGAN')\n",
    "    \n",
    "sample_figure_path = 'result/figures/info_BEGAN/'\n",
    "model_path = 'result/model/info_BEGAN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 [>                    ] 928/202599, loss: d=0.6920, g=0.9277"
     ]
    }
   ],
   "source": [
    "while epoch < epoch_size:\n",
    "    epoch += 1\n",
    "    \n",
    "    d_loss = []\n",
    "    g_loss = []\n",
    "    \n",
    "    batch_count = 0    \n",
    "    status = ('start training')\n",
    "    sys.stdout.write(status)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "    shuffle_files = file_names[np.random.permutation(range(len(file_names)))]\n",
    "    for step in range(count):\n",
    "        \n",
    "        \n",
    "        feed_dict = {}\n",
    "        start_index = step * batch_size * len(gpu_num)\n",
    "        for i in range(len(gpu_num)):\n",
    "            s = start_index + i * batch_size\n",
    "            e = s + batch_size\n",
    "                        \n",
    "            batch_files = shuffle_files[s:e]\n",
    "            batch_train = batch_from_dataset(batch_files, image_width, image_height)\n",
    "            batch_train = batch_train.astype(np.float32) * 2 - 1\n",
    "            batch_target = file_tags[s:e]\n",
    "            batch_count += len(batch_train)\n",
    "\n",
    "            batch_z_var = np.random.uniform(-1, 1, size=(len(batch_train), z_var)).astype(np.float32)\n",
    "            batch_z_category = np.random.randint(0, 2, size=(len(batch_train), z_category))\n",
    "            \n",
    "            \n",
    "            feed_dict[z_var_list[i]] = batch_z_var\n",
    "            feed_dict[z_category_list[i]] = batch_z_category\n",
    "            feed_dict[x_real_list[i]] = batch_train\n",
    "            feed_dict[y_list[i]] = batch_target\n",
    "        \n",
    "        _, loss_d, loss_g = sess.run([K_Update, Loss_D, Loss_G], feed_dict=feed_dict)\n",
    "        \n",
    "        d_loss += [loss_d]\n",
    "        g_loss += [loss_g]\n",
    "\n",
    "        \n",
    "        if (step+1) % display_count == 0:\n",
    "            g_fake = sess.run(x_fake_list[0], feed_dict={z_list[0]: z_sample})\n",
    "            e_real, d_real = sess.run([encode_real_list[0], decode_real_list[0]], \n",
    "                                      feed_dict={x_real_list[0]: image_sample})\n",
    "            '''\n",
    "            left, right = e_real[[0, -1]]\n",
    "            interpolate_z = []\n",
    "            for ratio in np.linspace(0, 1, 10):\n",
    "                interpolate_z.append(slerp(ratio, left, right))\n",
    "            d_inter = sess.run(D_Inter, feed_dict={Z: interpolate_z})\n",
    "            '''\n",
    "            \n",
    "            display.clear_output(wait=True)\n",
    "            DisplayHorizontal([ArrayToImage((x * 0.5 + 0.5) * 255) for x in np.concatenate([g_fake, image_sample, d_real], axis=0)], depth=3, figsize=(16, 6))\n",
    "            print('Epoch: %d, Count: %d' % (epoch+1, step+1))\n",
    "            display.display(plt.gcf())\n",
    "            plt.savefig(sample_figure_path + 'info_BEGAN_epoch_%d_batch_%d.png' % (epoch, step+1))\n",
    "            plt.close()\n",
    "        else:\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.flush()\n",
    "        status = ((\"Epoch: %d [%-\" + str(display_with + 1) + \"s] %d/%d, loss: d=%.4f, g=%.4f\") %\n",
    "          (epoch, '=' * int(batch_count / file_size * display_with) + '>', batch_count, file_size, np.mean(loss_d), np.mean(loss_g)))\n",
    "        sys.stdout.write(status)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        \n",
    "    sess.run(LR_Update)\n",
    "    saver.save(sess, model_path + 'info_BEGAN_CelebA.ckpt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
